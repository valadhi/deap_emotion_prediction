{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  video_id    emotion       mae  \\\n",
      "0             0       0.0    Valence -2.323249   \n",
      "1             1       0.0    Arousal -1.794769   \n",
      "2             2       0.0  Dominance -1.772289   \n",
      "3             3       0.0     Liking -0.792702   \n",
      "4             4       1.0    Valence -2.621139   \n",
      "..          ...       ...        ...       ...   \n",
      "119         119      30.0     Liking -2.264043   \n",
      "120         120      31.0    Valence -1.674095   \n",
      "121         121      31.0    Arousal -1.272534   \n",
      "122         122      31.0  Dominance -1.164978   \n",
      "123         123      31.0     Liking -2.207026   \n",
      "\n",
      "                                         best_features  \n",
      "0    ['bpm, rmssd, pnn20, sd1, breathingrate, CDA.n...  \n",
      "1                               ['bpm, pnn20, hr_mad']  \n",
      "2                                ['ibi, sd2, CDA.SCR']  \n",
      "3    ['bpm, ibi, sdsd, hr_mad, s, sd1/sd2, CDA.SCR,...  \n",
      "4                           ['sd1/sd2, breathingrate']  \n",
      "..                                                 ...  \n",
      "119                                 ['pnn50, sd1/sd2']  \n",
      "120                                     ['pnn50, sd2']  \n",
      "121                              ['ibi, pnn20, pnn50']  \n",
      "122  ['bpm, sdnn, rmssd, hr_mad, breathingrate, CDA...  \n",
      "123  ['ibi, breathingrate, CDA.nSCR, CDA.Latency, C...  \n",
      "\n",
      "[124 rows x 5 columns]\n",
      "     Unnamed: 0  video_id    emotion       mae  \\\n",
      "0             0       0.0    Valence -1.080963   \n",
      "1             1       0.0    Arousal -0.997103   \n",
      "2             2       0.0  Dominance -1.057018   \n",
      "3             3       0.0     Liking -1.332897   \n",
      "4             4       1.0    Valence -1.032720   \n",
      "..          ...       ...        ...       ...   \n",
      "155         155      38.0     Liking -1.332554   \n",
      "156         156      39.0    Valence -1.039869   \n",
      "157         157      39.0    Arousal -1.323874   \n",
      "158         158      39.0  Dominance -1.308562   \n",
      "159         159      39.0     Liking -1.530922   \n",
      "\n",
      "                                         best_features  \n",
      "0       ['CDA.ISCR, TTP.AmpSum, Global.MaxDeflection']  \n",
      "1    ['breathingrate, CDA.nSCR, CDA.AmpSum, TTP.Lat...  \n",
      "2                     ['sdnn, hr_mad, s, TTP.Latency']  \n",
      "3                                         ['TTP.nSCR']  \n",
      "4    ['bpm, ibi, pnn20, sd2, s, breathingrate, CDA....  \n",
      "..                                                 ...  \n",
      "155                    ['bpm, pnn20, pnn50, TTP.nSCR']  \n",
      "156  ['sdsd, CDA.nSCR, TTP.Latency, TTP.AmpSum, Glo...  \n",
      "157  ['bpm, ibi, sdnn, pnn50, sd1, sd1/sd2, CDA.Lat...  \n",
      "158  ['pnn20, pnn50, hr_mad, TTP.Latency, Global.Ma...  \n",
      "159            ['pnn20, hr_mad, Global.MaxDeflection']  \n",
      "\n",
      "[160 rows x 5 columns]\n",
      "     Unnamed: 0  video_id    emotion       mae  \\\n",
      "0             0       0.0    Valence -2.386359   \n",
      "1             1       0.0    Arousal -1.944464   \n",
      "2             2       0.0  Dominance -1.717359   \n",
      "3             3       0.0     Liking -0.876652   \n",
      "4             4       1.0    Valence -2.592519   \n",
      "..          ...       ...        ...       ...   \n",
      "119         119      30.0     Liking -2.363423   \n",
      "120         120      31.0    Valence -1.611160   \n",
      "121         121      31.0    Arousal -1.118356   \n",
      "122         122      31.0  Dominance -1.120611   \n",
      "123         123      31.0     Liking -1.943529   \n",
      "\n",
      "                                         best_features  \n",
      "0    ['bpm, ibi, sdsd, breathingrate, CDA.nSCR, CDA...  \n",
      "1                                    ['breathingrate']  \n",
      "2    ['bpm, ibi, sdsd, s, sd1/sd2, CDA.nSCR, CDA.La...  \n",
      "3    ['pnn50, sd1, CDA.nSCR, CDA.Latency, CDA.AmpSu...  \n",
      "4                                    ['breathingrate']  \n",
      "..                                                 ...  \n",
      "119                                          ['pnn20']  \n",
      "120  ['bpm, ibi, sd2, breathingrate, CDA.SCR, CDA.I...  \n",
      "121  ['pnn20, sd1/sd2, CDA.nSCR, CDA.Latency, CDA.A...  \n",
      "122  ['pnn20, breathingrate, CDA.Latency, CDA.AmpSu...  \n",
      "123  ['ibi, hr_mad, sd1, CDA.nSCR, CDA.Latency, CDA...  \n",
      "\n",
      "[124 rows x 5 columns]\n",
      "     Unnamed: 0  video_id    emotion       mae  \\\n",
      "0             0       0.0    Valence -1.041919   \n",
      "1             1       0.0    Arousal -1.076788   \n",
      "2             2       0.0  Dominance -1.231606   \n",
      "3             3       0.0     Liking -1.221563   \n",
      "4             4       1.0    Valence -1.126005   \n",
      "..          ...       ...        ...       ...   \n",
      "155         155      38.0     Liking -1.283455   \n",
      "156         156      39.0    Valence -0.959354   \n",
      "157         157      39.0    Arousal -1.495188   \n",
      "158         158      39.0  Dominance -1.307549   \n",
      "159         159      39.0     Liking -1.626918   \n",
      "\n",
      "                                         best_features  \n",
      "0                        ['CDA.PhasicMax, TTP.AmpSum']  \n",
      "1    ['ibi, CDA.nSCR, CDA.Latency, TTP.Latency, Glo...  \n",
      "2             ['pnn20, sd1/sd2, Global.MaxDeflection']  \n",
      "3                        ['CDA.PhasicMax, TTP.AmpSum']  \n",
      "4                                          ['sd1/sd2']  \n",
      "..                                                 ...  \n",
      "155  ['bpm, ibi, sdsd, hr_mad, s, sd1/sd2, CDA.nSCR...  \n",
      "156  ['sd1/sd2, breathingrate, CDA.nSCR, CDA.Latenc...  \n",
      "157                 ['sdsd, CDA.Latency, TTP.Latency']  \n",
      "158  ['sdsd, pnn50, CDA.SCR, CDA.ISCR, CDA.PhasicMa...  \n",
      "159  ['s, CDA.Latency, TTP.nSCR, Global.MaxDeflecti...  \n",
      "\n",
      "[160 rows x 5 columns]\n",
      "     Unnamed: 0  video_id    emotion       mae  \\\n",
      "0             0       0.0    Valence -2.323249   \n",
      "1             1       0.0    Arousal -1.794769   \n",
      "2             2       0.0  Dominance -1.772289   \n",
      "3             3       0.0     Liking -0.792702   \n",
      "4             4       1.0    Valence -2.621139   \n",
      "..          ...       ...        ...       ...   \n",
      "119         119      30.0     Liking -2.264043   \n",
      "120         120      31.0    Valence -1.674095   \n",
      "121         121      31.0    Arousal -1.272534   \n",
      "122         122      31.0  Dominance -1.164978   \n",
      "123         123      31.0     Liking -2.207026   \n",
      "\n",
      "                                         best_features  \n",
      "0    ['bpm, rmssd, pnn20, sd1, breathingrate, CDA.n...  \n",
      "1                               ['bpm, pnn20, hr_mad']  \n",
      "2                                ['ibi, sd2, CDA.SCR']  \n",
      "3    ['bpm, ibi, sdsd, hr_mad, s, sd1/sd2, CDA.SCR,...  \n",
      "4                           ['sd1/sd2, breathingrate']  \n",
      "..                                                 ...  \n",
      "119                                 ['pnn50, sd1/sd2']  \n",
      "120                                     ['pnn50, sd2']  \n",
      "121                              ['ibi, pnn20, pnn50']  \n",
      "122  ['bpm, sdnn, rmssd, hr_mad, breathingrate, CDA...  \n",
      "123  ['ibi, breathingrate, CDA.nSCR, CDA.Latency, C...  \n",
      "\n",
      "[124 rows x 5 columns]\n",
      "video 0.0\n",
      "<class 'float'>\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlad\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import core.main as main\n",
    "from sklearn import preprocessing\n",
    "\n",
    "gname_map = {'participant': 'Participant_id', 'video': 'Experiment_id'}\n",
    "gname_sortmap = {'participant': 'Experiment_id', 'video': 'Participant_id'}\n",
    "\n",
    "facet_group_map = {'participant': 'video', 'video': 'participant'}\n",
    "\n",
    "def run_tests_for_emotions(clean_frame, group_name, estimator):\n",
    "    feature_importance_data = []\n",
    "    for video_id, group_data in clean_frame.groupby([group_name]):\n",
    "        feats = group_data.drop(columns=['participant', 'video'])\n",
    "\n",
    "        # scale values\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        feats[feats.columns] = scaler.fit_transform(feats[feats.columns])\n",
    "        input_data = feats.values.tolist()\n",
    "        feature_names = feats.columns.values\n",
    "        print(feature_names)\n",
    "        for emotion in ['Valence', 'Arousal', 'Dominance', 'Liking']:\n",
    "            ratings = pd.read_csv('metadata_csv/participant_ratings.csv')\n",
    "            target_emotion = ratings[(ratings[gname_map[group_name]] == 1)].sort_values(\n",
    "                by=[gname_sortmap[group_name]])[emotion].to_list()\n",
    "\n",
    "            test_score, importance = getattr(main, estimator)(input_data, target_emotion)\n",
    "            metric_names = list(test_score.keys())\n",
    "            metric_values = list(test_score.values())\n",
    "\n",
    "            feature_importance_data.append([video_id, emotion] + metric_values\n",
    "                                           # + importance\n",
    "                                           )\n",
    "    results_frame = pd.DataFrame(feature_importance_data,\n",
    "                                 columns=['video_id', 'emotion'] + metric_names\n",
    "                                         # + feature_names.tolist()\n",
    "                                 )\n",
    "    return results_frame\n",
    "\n",
    "def run_tests_for_emotions_feat_selector(clean_frame, group_name, estimator):\n",
    "    feature_importance_data = []\n",
    "    for video_id, group_data in clean_frame.groupby([group_name]):\n",
    "        print(\"{0} {1}\".format(group_name, video_id))\n",
    "        # continue\n",
    "        feats = group_data.drop(columns=['participant', 'video'])\n",
    "\n",
    "        # scale values\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        feats[feats.columns] = scaler.fit_transform(feats[feats.columns])\n",
    "        input_data = feats.values.tolist()\n",
    "        feature_names = feats.columns.values\n",
    "        # print(feature_names)\n",
    "        for emotion in ['Valence', 'Arousal', 'Dominance', 'Liking']:\n",
    "            # ratings = pd.read_csv('metadata_csv/participant_ratings.csv')\n",
    "            # target_emotion = ratings[(ratings[gname_map[group_name]] == 1)].sort_values(\n",
    "            #     by=[gname_sortmap[group_name]])[emotion].to_list()\n",
    "            # target_emotion = [t for i, t in enumerate(target_emotion) if i not in main.exclude_participant]\n",
    "\n",
    "            exclude = True if group_name == 'video' else False\n",
    "            target_emotion = get_ratings(emotion, exclude, video_id, group_name, facet_group_map[group_name])\n",
    "\n",
    "\n",
    "            test_score, feat_idx = getattr(main, estimator)(input_data, target_emotion)\n",
    "            best_features = [', '.join([feature_names[i] for i in feat_idx])]\n",
    "            feature_importance_data.append([video_id, emotion, test_score, best_features])\n",
    "\n",
    "    results_frame = pd.DataFrame(feature_importance_data,\n",
    "                                 columns=['video_id', 'emotion', 'mae', 'best_features'])\n",
    "    return results_frame\n",
    "\n",
    "def get_ratings(emotion, exclude, selector_id, in_column, groupby):\n",
    "    ratings = pd.read_csv('metadata_csv/participant_ratings.csv')\n",
    "    print(ratings)\n",
    "    target_emotion = ratings[(ratings[in_column] == selector_id)].sort_values(\n",
    "        by=[groupby])[emotion].to_list()\n",
    "    if exclude:\n",
    "        target_emotion = [t for i, t in enumerate(target_emotion) if i not in main.exclude_participant]\n",
    "    return target_emotion\n",
    "\n",
    "\n",
    "config = [\n",
    "    # # # # # # # # # # # # REGRESSORS # # # # # # # # # # # # #\n",
    "    # # # # all features # # # #\n",
    "    # {'path': 'participant_all_feats_forest.csv',\n",
    "    #  'grouping': 'participant', 'estimator': 'run_test_forest'},\n",
    "    # {'path': 'video_all_feats_forest.csv',\n",
    "    #  'grouping': 'video', 'estimator': 'run_test_forest'},\n",
    "    # {'path': 'participant_all_feats_xgboost.csv',\n",
    "    #  'grouping': 'participant', 'estimator': 'run_test_xgboost'},\n",
    "    # {'path': 'video__all_feats_xgboost.csv',\n",
    "    #  'grouping': 'video', 'estimator': 'run_test_xgboost'},\n",
    "    # {'path': 'participant_all_feats_regression.csv',\n",
    "    #  'grouping': 'participant', 'estimator': 'run_test_regression'},\n",
    "    # {'path': 'video__all_feats_regression.csv',\n",
    "    #  'grouping': 'video', 'estimator': 'run_test_regression'},\n",
    "    # # # # best features # # # #\n",
    "    {'path': 'participant_best_score_regression.csv',\n",
    "     'grouping': 'participant', 'estimator': 'run_test_regression_feature_selector'},\n",
    "    {'path': 'video_best_score_regression.csv',\n",
    "     'grouping': 'video', 'estimator': 'run_test_regression_feature_selector'},\n",
    "    {'path': 'participant_best_score_forest.csv',\n",
    "     'grouping': 'participant', 'estimator': 'run_test_forest_feature_selector'},\n",
    "    {'path': 'video_best_score_forest.csv',\n",
    "     'grouping': 'video', 'estimator': 'run_test_forest_feature_selector'},\n",
    "    {'path': 'participant_best_score_regression.csv',\n",
    "     'grouping': 'participant', 'estimator': 'run_test_xgboost_feature_selector'},\n",
    "    {'path': 'video_best_score_xgboost.csv',\n",
    "     'grouping': 'video', 'estimator': 'run_test_regression_feature_selector'},\n",
    "    # # # # # # # # # # # CLASSIFIERS # # # # # # # # # # # # #\n",
    "    # # # # all features # # # #\n",
    "    # # # # best features # # # #\n",
    "]\n",
    "\n",
    "for c in config:\n",
    "    c['path'] = os.path.join('results', c['path'])\n",
    "    if os.path.isfile(c['path']):\n",
    "        feats_by_participant = pd.read_csv(c['path'])\n",
    "        print(feats_by_participant)\n",
    "    else:\n",
    "        hr_path = \"hr_features.pkl\"\n",
    "        eda_path = \"eda_features.pkl\"\n",
    "        if os.path.isfile(hr_path):\n",
    "            hr_features_frame = pd.read_pickle(hr_path)\n",
    "        if os.path.isfile(eda_path):\n",
    "            eda_features_frame = pd.read_pickle(eda_path)\n",
    "\n",
    "        # print(eda_features_frame.groupby(['participant'])['video'].count())\n",
    "        # print(hr_features_frame.groupby(['participant'])['video'].count())\n",
    "\n",
    "        eda_features_frame = eda_features_frame.drop(columns=['participant', 'video'])\n",
    "        full_feature_data = pd.concat([hr_features_frame, eda_features_frame], axis=1)\n",
    "        df = full_feature_data\n",
    "\n",
    "        # what do about missing/failing feature values\n",
    "        clean_frame = df.fillna(0)\n",
    "        group_name = c['grouping']\n",
    "        estimator = c['estimator']\n",
    "        feature_importance_data = []\n",
    "        for video_id, group_data in clean_frame.groupby([group_name]):\n",
    "            print(\"{0} {1}\".format(group_name, video_id))\n",
    "            # continue\n",
    "            feats = group_data.drop(columns=['participant', 'video'])\n",
    "\n",
    "            # scale values\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            feats[feats.columns] = scaler.fit_transform(feats[feats.columns])\n",
    "            input_data = feats.values.tolist()\n",
    "            feature_names = feats.columns.values\n",
    "            # print(feature_names)\n",
    "            for emotion in ['Valence', 'Arousal', 'Dominance', 'Liking']:\n",
    "                exclude = True if group_name == 'video' else False\n",
    "                target_val = int(video_id)\n",
    "                target_col = group_name\n",
    "                groupby = facet_group_map[group_name]\n",
    "                target_val = int(target_val) + 1\n",
    "                ratings = pd.read_csv('metadata_csv/participant_ratings.csv')\n",
    "                target_emotion = ratings[(ratings[target_col] == target_val)].sort_values(\n",
    "                    by=[groupby])[emotion].to_list()\n",
    "                if exclude:\n",
    "                    target_emotion = [t for i, t in enumerate(target_emotion) if i not in main.exclude_participant]\n",
    "\n",
    "                print(type(target_emotion[0]))\n",
    "                binarize = [0 if (float(e) < 5.0) else 1 for e in target_emotion]\n",
    "                print(binarize)\n",
    "\n",
    "                import sys\n",
    "                sys.exit(0)\n",
    "\n",
    "                test_score, feat_idx = getattr(main, estimator)(input_data, target_emotion)\n",
    "                best_features = [', '.join([feature_names[i] for i in feat_idx])]\n",
    "                feature_importance_data.append([video_id, emotion, test_score, best_features])\n",
    "\n",
    "        results_frame = pd.DataFrame(feature_importance_data,\n",
    "                                     columns=['video_id', 'emotion', 'mae', 'best_features'])\n",
    "\n",
    "        # results_frame.to_csv(c['path'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}